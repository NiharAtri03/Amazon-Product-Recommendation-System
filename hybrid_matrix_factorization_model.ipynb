{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0c1203-6351-48a2-9e00-6985c8a2bd5d",
   "metadata": {},
   "source": [
    "# Hybrid Matrix Factorization (LightFM)\n",
    "\n",
    "Now, we will be implementing a hybrid Matrix Factorization model through the LightFM Library. Previously, we only took into account whether a user reviewed a product and the rating they gave it. However, our dataset has a lot of other features about the products and users that could help with our analysis (a product's store, price, category, etc). This hybrid model learns the embeddings for these additional features on top of the user and item embeddings from plain Matrix Factorization. This allows hybrid models to get the best of Collaborative Filtering and Content-based Filtering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43df6b8f-a052-46dd-b22b-e9359841dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightfm in /opt/conda/lib/python3.10/site-packages (1.17)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.24.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lightfm) (2.32.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lightfm) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lightfm) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0621cd11-c06d-4168-8811-e799f3b51dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/implicit/gpu/__init__.py:13: UserWarning: CUDA extension is built, but disabling GPU support because of 'Cuda Error: CUDA driver version is insufficient for CUDA runtime version (/project/./implicit/gpu/utils.h:71)'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import gcsfs\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import gc\n",
    "\n",
    "from implicit.evaluation import mean_average_precision_at_k, precision_at_k, AUC_at_k\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from scipy.sparse import coo_matrix, save_npz, load_npz, vstack, hstack, csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from glob import glob\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896d813-2b5d-45a4-83d8-12a3a12a6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.float_format')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d012d167-551f-462d-b0f8-17f074dc56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"gs://amazon-reviews-project/train_df.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87d615-e4b5-417e-a8d9-bf1669e55541",
   "metadata": {},
   "source": [
    "Similarily with the original Matrix Factorization model, we want to remove users/products that do not add any signal to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d153fe66-836e-4878-9c4a-2103b0678aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = train_df['user_id'].value_counts()\n",
    "product_counts = train_df['parent_asin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9672919a-8e86-47cd-a88b-8de699bb7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_reviews = 5\n",
    "\n",
    "valid_users = user_counts[user_counts > min_reviews].index\n",
    "valid_products = product_counts[product_counts > min_reviews].index\n",
    "\n",
    "filtered_train_df = train_df[train_df[\"user_id\"].isin(valid_users) & train_df[\"parent_asin\"].isin(valid_products)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efbbb471-9f09-4419-a070-0386422edff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_train_df = filtered_train_df.drop(['timestamp', 'price_missing', 'datetime', 'year'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729239a-2dfd-463a-ba23-49c019d9ad1c",
   "metadata": {},
   "source": [
    "We also want to calculate confidence scores for each user-product interaction, using the optimized formula from the Matrix Factorization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c973a2-a9f5-4f8a-abe1-2864be1b9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10.0\n",
    "filtered_train_df[\"confidence\"] = 1.0 + alpha * np.log1p(filtered_train_df[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814592b-6dcd-454a-a1a5-c85865b61a4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, we have to decide which of the features we can input as user and item metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d757d4a2-2ba9-44fa-bf41-bb393211349a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>history</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>price</th>\n",
       "      <th>store</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFJTRBXMURLHS5EGNXLUHDHIZRFQ</td>\n",
       "      <td>B096WPNG8Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Patio_Lawn_and_Garden</td>\n",
       "      <td>Mosser Lee ML0560 Spanish Moss, 250 Cubic Inches</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Mosser Lee</td>\n",
       "      <td>18.917595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFJTRBXMURLHS5EGNXLUHDHIZRFQ</td>\n",
       "      <td>B000BQT5IG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>B096WPNG8Q</td>\n",
       "      <td>Patio_Lawn_and_Garden</td>\n",
       "      <td>Combat Indoor and Outdoor Ant Killing Gel, 27 ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.48</td>\n",
       "      <td>Combat</td>\n",
       "      <td>14.862944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFJTRBXMURLHS5EGNXLUHDHIZRFQ</td>\n",
       "      <td>B002FGU2MI</td>\n",
       "      <td>4.0</td>\n",
       "      <td>B096WPNG8Q B000BQT5IG</td>\n",
       "      <td>Patio_Lawn_and_Garden</td>\n",
       "      <td>SWIMLINE HYDROTOOLS Mini Venturi Pool &amp; Spa Va...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>16.93</td>\n",
       "      <td>Swimline</td>\n",
       "      <td>17.094379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEFKF6R2GUSK2AWPSWRR4ZO36JVQ</td>\n",
       "      <td>B073V7N6RQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Patio_Lawn_and_Garden</td>\n",
       "      <td>Raisman Rewind Recoil Starter Assembly Compati...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>25.99</td>\n",
       "      <td>Raisman</td>\n",
       "      <td>18.917595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEFKF6R2GUSK2AWPSWRR4ZO36JVQ</td>\n",
       "      <td>B01J0RIRUS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>B073V7N6RQ</td>\n",
       "      <td>Patio_Lawn_and_Garden</td>\n",
       "      <td>AUTOKAY Recoil Pull Start Compatible with Brig...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>AUTOKAY</td>\n",
       "      <td>17.094379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating                history  \\\n",
       "0  AFJTRBXMURLHS5EGNXLUHDHIZRFQ  B096WPNG8Q     5.0                   None   \n",
       "1  AFJTRBXMURLHS5EGNXLUHDHIZRFQ  B000BQT5IG     3.0             B096WPNG8Q   \n",
       "2  AFJTRBXMURLHS5EGNXLUHDHIZRFQ  B002FGU2MI     4.0  B096WPNG8Q B000BQT5IG   \n",
       "3  AEFKF6R2GUSK2AWPSWRR4ZO36JVQ  B073V7N6RQ     5.0                   None   \n",
       "4  AEFKF6R2GUSK2AWPSWRR4ZO36JVQ  B01J0RIRUS     4.0             B073V7N6RQ   \n",
       "\n",
       "                category                                              title  \\\n",
       "0  Patio_Lawn_and_Garden   Mosser Lee ML0560 Spanish Moss, 250 Cubic Inches   \n",
       "1  Patio_Lawn_and_Garden  Combat Indoor and Outdoor Ant Killing Gel, 27 ...   \n",
       "2  Patio_Lawn_and_Garden  SWIMLINE HYDROTOOLS Mini Venturi Pool & Spa Va...   \n",
       "3  Patio_Lawn_and_Garden  Raisman Rewind Recoil Starter Assembly Compati...   \n",
       "4  Patio_Lawn_and_Garden  AUTOKAY Recoil Pull Start Compatible with Brig...   \n",
       "\n",
       "   average_rating  price       store  confidence  \n",
       "0             4.6   4.97  Mosser Lee   18.917595  \n",
       "1             4.4   5.48      Combat   14.862944  \n",
       "2             3.9  16.93    Swimline   17.094379  \n",
       "3             4.5  25.99     Raisman   18.917595  \n",
       "4             4.0  16.99     AUTOKAY   17.094379  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88c944-ecd8-46a3-9f85-6971b3e45832",
   "metadata": {},
   "source": [
    "History represents a list of the items each user previously reviewed, which makes it a perfect way to understand user behavior. Thus, we will encode it as a user metadata feature. Currently, history is stored as a space seperated list of product ids. We want to convert this into a python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1f4095-2f8b-469a-b3a7-dddc3f8113c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_train_df[\"history\"] = filtered_train_df[\"history\"].fillna(\"\").apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77aa9d72-9a6a-4537-83ea-20c0f7513b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          []\n",
       "1                [B096WPNG8Q]\n",
       "2    [B096WPNG8Q, B000BQT5IG]\n",
       "3                          []\n",
       "4                [B073V7N6RQ]\n",
       "Name: history, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_df[\"history\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fbff4-713e-4ff0-935f-1b06f52de0ae",
   "metadata": {},
   "source": [
    "For item metadata, we have category, title, average_rating, price, and store. However, we want to make sure the metadata we include will add signal to the data and not noise. We also want to make sure the feature doesn't unnecessarily increase the complexity of the model (too many different categories). For these reasons, we will exclude title (too many unique values). Store could potentially add signal, but let's make sure it won't make the data too high-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca71fc5-5872-4030-b961-21713e72b3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 200 most popular stores cover 23.10% of interactions.\n",
      "The other stores cover 76.90% of interactions.\n"
     ]
    }
   ],
   "source": [
    "store_counts = filtered_train_df['store'].value_counts()\n",
    "\n",
    "top_200_stores = store_counts.head(200)\n",
    "\n",
    "top_200_total = top_200_stores.sum()\n",
    "\n",
    "other_total = store_counts.iloc[200:].sum()\n",
    "\n",
    "print(f\"The top 200 most popular stores cover {top_200_total / store_counts.sum():.2%} of interactions.\")\n",
    "print(f\"The other stores cover {other_total / store_counts.sum():.2%} of interactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d2112-9b38-4642-89c9-679f81c2021a",
   "metadata": {},
   "source": [
    "This means there are too many unique store names so adding it as a item metadata feature would significantly increase the dimensionality of the data and drown out signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca18020-519f-48c4-b830-b470a6dd9f3c",
   "metadata": {},
   "source": [
    "Now, it makes sense that the price, average product rating, and category would affect whether a user would enjoy a product. However, LightFM only accepts categories as metadata input. Thus, we will convert price and average product rating (currently floats) into bins based on quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe7b71e-1234-402e-88b2-cc97ba4b58e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert price column to bins\n",
    "filtered_train_df[\"price\"] = filtered_train_df[\"price\"].replace(-1, np.nan)\n",
    "\n",
    "filtered_train_df[\"price_bins\"], price_bin_edges = pd.qcut(filtered_train_df[\"price\"], q=5, \n",
    "                                                           labels=[\"Very Cheap\", \"Cheap\", \"Medium\", \"Expensive\", \"Very Expensive\"],\n",
    "                                                           retbins=True)\n",
    "\n",
    "filtered_train_df[\"price_bins\"] = filtered_train_df[\"price_bins\"].cat.add_categories(\"Missing\")\n",
    "filtered_train_df[\"price_bins\"] = filtered_train_df[\"price_bins\"].fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dfc066c-f06a-47c7-884d-cf0170ab3e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.  ,    11.47,    17.75,    25.97,    44.92, 11099.  ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b902ee5d-6f84-434b-b985-7768f37d6bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rating labels are more positive since rating data is positively skewed (as seen in the bin edges)\n",
    "rating_labels =  [\"Negative\", \"Positive\", \"Very Positive\", \"Near Perfect\", \"Perfect\"]\n",
    "\n",
    "filtered_train_df['avg_rating_bin'], ratings_bin_edges= pd.qcut(filtered_train_df['average_rating'], q=5, labels=rating_labels, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5eca63d-9a18-4b56-8807-cc46817cbeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 4.2, 4.4, 4.5, 4.7, 5. ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e3f538-168d-4dc0-8d78-8e9ee9ca7212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_bins</th>\n",
       "      <th>avg_rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very Cheap</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very Cheap</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheap</td>\n",
       "      <td>Very Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expensive</td>\n",
       "      <td>Impartial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cheap</td>\n",
       "      <td>Very Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_bins avg_rating_bin\n",
       "0  Very Cheap           Good\n",
       "1  Very Cheap       Negative\n",
       "2       Cheap  Very Negative\n",
       "3   Expensive      Impartial\n",
       "4       Cheap  Very Negative"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_df[[\"price_bins\", \"avg_rating_bin\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753947dc-414a-4109-b08a-064795784da8",
   "metadata": {},
   "source": [
    "The category column only has 14 categories, so we can keep it as is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c680b-5729-4d00-95fe-4754353baf1f",
   "metadata": {},
   "source": [
    "We have cleaned all the features we want to use for our item and user metadata. Now, we want build user and item feature matrices that are compatible with LightFM so we can train a hybrid recommendation model that leverages both interaction data and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d558a57c-fff2-40ff-87a2-9d158b2863e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up notebook memory\n",
    "del train_df, user_counts, product_counts, valid_users, valid_products, price_bin_edges, ratings_bin_edges\n",
    "gc.collect()\n",
    "\n",
    "filtered_train_df = filtered_train_df.drop([\"price\", \"average_rating\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12ed04e-8512-4ece-b8bb-6a5f1047d688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build a mapping between product id and category\n",
    "asin_to_category = filtered_train_df.drop_duplicates(\"parent_asin\").set_index(\"parent_asin\")[\"category\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ba6245-cbd8-440d-88e1-7d21fb2f8273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the history list of product ids to list of categories (offers more information for the model)\n",
    "user_to_cat_tokens = defaultdict(set)\n",
    "\n",
    "for row in filtered_train_df.itertuples():\n",
    "    uid = row.user_id\n",
    "    for asin in row.history:\n",
    "        cat = asin_to_category.get(asin)\n",
    "        if pd.notna(cat):\n",
    "            user_to_cat_tokens[uid].add(f\"user_cat={cat}\")\n",
    "\n",
    "user_to_cat_tokens = {uid: sorted(list(tokens)) for uid, tokens in user_to_cat_tokens.items()}\n",
    "\n",
    "filtered_train_df[\"user_category_tokens\"] = filtered_train_df[\"user_id\"].map(user_to_cat_tokens).fillna(\"\").apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c4f2dcb-2068-4141-9167-df64399cb54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cleaning up notebook memory\n",
    "filtered_train_df = filtered_train_df.drop([\"history\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ee353d-350a-4041-826e-8de73d2d5d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert categorical columns to token format (\"cat = Video Games\", \"price_bin = Cheap\", \"avg_rating_bin = Perfect\") for proper indexing (LightFM Dataset\n",
    "# objects expect this format)\n",
    "# need to use vectorized operations for memory efficiency\n",
    "filtered_train_df[\"cat_token\"] = \"cat=\" + filtered_train_df[\"category\"].astype(str)\n",
    "filtered_train_df[\"price_token\"] = \"price_bin=\" + filtered_train_df[\"price_bins\"].astype(str)\n",
    "filtered_train_df[\"rating_token\"] = \"avg_rating_bin=\" + filtered_train_df[\"avg_rating_bin\"].astype(str)\n",
    "\n",
    "\n",
    "filtered_train_df[\"item_feature_tokens\"] = (filtered_train_df[\"cat_token\"].str.\n",
    "                                            cat([filtered_train_df[\"price_token\"], filtered_train_df[\"rating_token\"]],sep=\"|\").str.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9f90314-1ce4-4f6a-b6c9-55ce6ba78422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cleaning up notebook memory\n",
    "filtered_train_df = filtered_train_df.drop([\"cat_token\", \"price_token\", \"rating_token\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4491fd7-c67c-4841-9bd6-22cd9686533e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit Dataset object with user/item IDs and the feature tokens so LightFM can properly index all user and item metadata features\n",
    "dataset = Dataset()\n",
    "\n",
    "interaction_user_ids = filtered_train_df[\"user_id\"].astype(str).unique()\n",
    "interaction_item_ids = filtered_train_df[\"parent_asin\"].astype(str).unique()\n",
    "\n",
    "dataset.fit(users = interaction_user_ids, items = interaction_item_ids,\n",
    "    user_features = sorted(set(token for tokens in filtered_train_df[\"user_category_tokens\"] for token in tokens)),\n",
    "    item_features = sorted(set(token for tokens in filtered_train_df[\"item_feature_tokens\"] for token in tokens))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d7b0e50-c38c-4287-8d55-7d6695658d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uses unique user and category metadata tokens to build sparse matrices that can be used as input to the fit() function\n",
    "all_user_ids = filtered_train_df[\"user_id\"].unique()\n",
    "\n",
    "user_feature_dict = {\n",
    "    user_id: user_to_cat_tokens.get(user_id, []) for user_id in all_user_ids\n",
    "}\n",
    "\n",
    "user_feature_tuples = list(user_feature_dict.items())\n",
    "item_feature_tuples = list(filtered_train_df.groupby(\"parent_asin\")[\"item_feature_tokens\"].last().items())\n",
    "\n",
    "user_features = dataset.build_user_features(user_feature_tuples)\n",
    "item_features = dataset.build_item_features(item_feature_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1c69823-c598-4bdc-83ff-c23f9f849495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interaction_tuples = list(zip(filtered_train_df[\"user_id\"], filtered_train_df[\"parent_asin\"], filtered_train_df[\"confidence\"]))\n",
    "\n",
    "interactions, weights = dataset.build_interactions(interaction_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c23e2ec6-821d-402a-9f23-781d8f6df808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"saved_models/lightfm_dataset.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0d44d-7ffd-4f27-9f04-67af598a4d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = LightFM(loss=\"warp\", no_components=64, learning_rate=0.05, item_alpha=1e-6, user_alpha=1e-6, random_state=42)\n",
    "\n",
    "model.fit(interactions = interactions, user_features = user_features, item_features = item_features, sample_weight = weights, epochs = 20,\n",
    "          num_threads = num_cores, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c3284-d454-4132-b9c4-2ce6cb657496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "with open(\"saved_models/lightfm_model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c70859f5-8504-469c-9015-d7f680939f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save all the matrices for evaluation\n",
    "save_npz(\"lightfm_user_features.npz\", user_features)\n",
    "save_npz(\"lightfm_item_features.npz\", item_features)\n",
    "save_npz(\"lightfm_interactions.npz\", interactions)\n",
    "save_npz(\"lightfm_weights.npz\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e60cc9-f408-48c8-bca0-cd47a4cbe9b4",
   "metadata": {},
   "source": [
    "Now, we have a trained LightFM model with its corresponding user features, item features, interaction matrices. We will use these matrices to evaluate the model against both the training and test data. We will use the below metrics to evaluate our model (note that we replace MAP with recall as LightFM does not support MAP):\n",
    "- Precision at k: Out of the top k items the model recommends for a user, how many are actually relevant (items the user interacted with or liked)?\n",
    "- Recall at K: Out of all the relevant items for a user, what percentage appear in the top k recommendations the model makes?\n",
    "- AUC at K: Measures the probability that, out of the top k recommendations, a randomly chosen relevant item is ranked higher than a randomly chosen irrelevant item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1816af09-d652-463d-9e37-cf3931b96f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read saved dataset object\n",
    "with open(\"saved_models/lightfm_dataset.pickle\", \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83208023-4064-4317-8f2c-7f6ab6cce277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read saved model\n",
    "with open(\"saved_models/lightfm_model.pickle\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1bf9942-7cf5-41ae-9f9a-7094aaba2ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_features = load_npz(\"saved_csr_matrices/lightfm_user_features.npz\")\n",
    "item_features = load_npz(\"saved_csr_matrices/lightfm_item_features.npz\")\n",
    "train_interactions = load_npz(\"saved_csr_matrices/lightfm_interactions.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b637062-b176-4814-8786-b0e17e97a64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_interactions = train_interactions.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f10896-1f52-447f-be7c-8bbfda295470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read test review data\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "all_files = fs.glob(\"amazon-reviews-project/test_data/*.csv.gz\")\n",
    "\n",
    "test_dfs = []\n",
    "\n",
    "for file in all_files:\n",
    "    base = os.path.basename(file).replace(\".csv.gz\", \"\")\n",
    "    category, _ = base.split('.', 1)\n",
    "\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        df = pd.read_csv(f, compression='gzip')\n",
    "        df['category'] = category\n",
    "\n",
    "    test_dfs.append(df)\n",
    "\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "508cfbd3-163b-4699-990b-2c376aa8ba13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get saved user/feature mappings from user-item matrix\n",
    "u_map, ufeat_map, i_map, ifeat_map = loaded_data.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9efd8a-de38-45f6-afbc-62e69b0e3112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only keep users/items present in the training mapping\n",
    "test_df = test_df[test_df[\"user_id\"].isin(u_map.keys()) & test_df[\"parent_asin\"].isin(i_map.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b589a1-fc84-49a6-a18e-0aa4dd366af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build same confidence matrix as in training\n",
    "alpha = 10.0\n",
    "test_df[\"confidence\"] = 1.0 + alpha * np.log1p(test_df[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081af4fb-d365-43d5-8e93-8292aeda1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build interaction tuples\n",
    "test_interaction_tuples = list(zip(test_df[\"user_id\"], test_df[\"parent_asin\"], test_df[\"confidence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59d8a60-9a6e-4192-939e-fd96d967772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build interaction matrix for test data\n",
    "test_interactions, test_weights = loaded_data.build_interactions(test_interaction_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c99a818b-b42d-4645-bed5-0ad432b36295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_interactions = test_interactions.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2572a4ec-1f13-47a6-958d-c01d6cea65f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Subset Training Data Evaluation (5000 users) ===\n",
      "Precision@10: 0.0105\n",
      "Recall@10:    0.0072\n",
      "AUC:          0.9739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on random sample of training data (5000 data points) as evaluating on entire training dataset is unfeasible\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "active_user_ids = np.where(train_interactions.getnnz(axis=1) > 5)[0]\n",
    "subset_user_ids = np.random.choice(active_user_ids, size=5000, replace=False)\n",
    "\n",
    "train_subset = train_interactions[subset_user_ids, :]\n",
    "user_features_subset = user_features[subset_user_ids, :]\n",
    "\n",
    "print(\"=== Subset Training Data Evaluation (5000 users) ===\")\n",
    "\n",
    "train_prec = precision_at_k(\n",
    "    loaded_model,\n",
    "    train_subset,\n",
    "    user_features=user_features_subset,\n",
    "    item_features=item_features,\n",
    "    k=10,\n",
    "    num_threads=num_cores\n",
    ").mean()\n",
    "print(f\"Precision@10: {train_prec:.4f}\")\n",
    "\n",
    "train_rec = recall_at_k(\n",
    "    loaded_model,\n",
    "    train_subset,\n",
    "    user_features=user_features_subset,\n",
    "    item_features=item_features,\n",
    "    k=10,\n",
    "    num_threads=num_cores\n",
    ").mean()\n",
    "print(f\"Recall@10:    {train_rec:.4f}\")\n",
    "\n",
    "train_auc = auc_score(\n",
    "    loaded_model,\n",
    "    train_subset,\n",
    "    user_features=user_features_subset,\n",
    "    item_features=item_features,\n",
    "    num_threads=num_cores\n",
    ").mean()\n",
    "print(f\"AUC:          {train_auc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88abd81b-3437-4d1f-b2ef-d72ea9434299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Subset Testing Data Evaluation (5000 users) ===\n",
      "Precision@10: 0.0041\n",
      "Recall@10:    0.0039\n",
      "AUC:          0.8668\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on random sample of testing data (5000 data points) as evaluating on entire testing dataset is unfeasible\n",
    "\n",
    "active_user_ids_test = np.where(test_interactions.getnnz(axis=1) > 5)[0]\n",
    "subset_user_ids_test = np.random.choice(active_user_ids_test, size=5000, replace=False)\n",
    "\n",
    "test_subset = test_interactions[subset_user_ids_test, :]\n",
    "user_features_subset_test = user_features[subset_user_ids_test, :]\n",
    "\n",
    "print(\"=== Subset Testing Data Evaluation (5000 users) ===\")\n",
    "\n",
    "test_prec = precision_at_k(\n",
    "    loaded_model,\n",
    "    test_subset,\n",
    "    user_features=user_features_subset_test,\n",
    "    item_features=item_features,\n",
    "    k=10,\n",
    "    num_threads=num_cores\n",
    ").mean()\n",
    "print(f\"Precision@10: {test_prec:.4f}\")\n",
    "\n",
    "test_rec = recall_at_k(\n",
    "    loaded_model,\n",
    "    test_subset,\n",
    "    user_features=user_features_subset_test,\n",
    "    item_features=item_features,\n",
    "    k=10,\n",
    "    num_threads=num_cores\n",
    ").mean()\n",
    "print(f\"Recall@10:    {test_rec:.4f}\")\n",
    "\n",
    "test_auc = auc_score(\n",
    "    loaded_model,\n",
    "    test_subset,\n",
    "    user_features=user_features_subset_test,\n",
    "    item_features=item_features,\n",
    "    num_threads=num_cores\n",
    ").mean()\n",
    "print(f\"AUC:          {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3469de0f-bd3f-4f7a-8aa6-44d3b98b8f09",
   "metadata": {},
   "source": [
    "Based on the testing data, we can see the LightFM model performed better than the plain matrix factorization model from previous notebooks on all metrics.\n",
    "\n",
    "Original MF Model:\n",
    "- Precision@10: 0.0039\n",
    "- MAP@10:       0.0019\n",
    "- AUC:          0.5020\n",
    "\n",
    "LightFM Model:\n",
    "- Precision@10: 0.0041\n",
    "- Recall@10:    0.0039\n",
    "- AUC:          0.8668\n",
    "\n",
    "Interpretation:\n",
    "- Precision@10: Only about 0.41% of the items in the top 10 recommendations per user are actually relevant \n",
    "- Recall@10: Only 0.39% of all the relevant items for a user appear in the top 10 recommendations the model makes\n",
    "- AUC: The model is very good at ranking relevant products higher than non relevant products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c210bb8-d830-4c19-b67c-47bf8bc400f4",
   "metadata": {},
   "source": [
    "We can see the LightFM model still struggles to recommend relevant items to users (low precision and recall for the top 10 recommendations). However, given the high AUC score, this model is significantly better at generally ranking relevant items over irrelevant items. This means that, while the model is unable to provide relevant recommendations, it has a much better understanding of the types of products thart users are not interested in interacting with, and ranks them lower. This improvement was due to the model incorporating user and product metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c768da-1353-4d72-ab49-23f8c39fd502",
   "metadata": {},
   "source": [
    "Out of the three models I experimented with (recommend the most popular items, matrix factorization, LightFM), LightFM performed the best in terms of understanding which items customers are more likely to engage with and which items customers are not interested in. However, the LightFM model also required more data cleaning, preprocessing, a large amount of compute, and training time for a marginal increase (this model took more than 20 hours to train). In a production setting, it may not be worth investing that much compute and time for marginal improvements, and rather we settle for a simple popularity recommendation method."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
